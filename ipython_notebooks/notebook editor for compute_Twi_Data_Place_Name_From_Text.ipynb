{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "associatedRecipe": "compute_Twi_Data_Place_Name_From_Text",
    "creator": "admin",
    "createdOn": 1666721788670,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 21,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Read recipe inputs\nTwi_Data_Split_Text_Clean_prepared \u003d dataiku.Dataset(\"Twi_Data_Split_Text_Clean_prepared\")\nTwi_Data_Split_Text_Clean_prepared_df \u003d Twi_Data_Split_Text_Clean_prepared.get_dataframe()\n\n"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### dropping nill values (about 600ish, hopefully doesn\u0027t make a big difference)"
      ]
    },
    {
      "execution_count": 19,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Twi_Data_Split_Text_Clean_prepared_df.dropna(inplace\u003dTrue)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### cleaning text_tweets"
      ]
    },
    {
      "execution_count": 12,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# make new column that says place_name\nplace_names \u003d []\n# TODO: loop through text and extract 1 or 2 words after \"I\u0027m at\"\nfor text in Twi_Data_Split_Text_Clean_prepared_df[\u0027tweet_text_clean\u0027]:\n    split_text \u003d text.lower().split()\n    if len(split_text) \u003d\u003d 1:\n        place_names.append(split_text[0])\n    elif split_text[0] \u003d\u003d \"i\u0027m\" and split_text[1] \u003d\u003d \u0027at\u0027:\n        index \u003d 4\n        if \u0027in\u0027 in split_text:\n            index \u003d split_text.index(\u0027in\u0027)\n        place_names.append(\u0027 \u0027.join(split_text[2:index]))\n    else:\n        place_names.append(\"no name\")"
      ],
      "outputs": []
    },
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Twi_Data_Split_Text_Clean_prepared_df[\u0027place_text_name\u0027] \u003d place_names"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Getting app name from the HTML"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 10,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\nTwi_Data_Place_Name_From_Text_df \u003d Twi_Data_Split_Text_Clean_prepared_df # For this sample code, simply copy input to output\n\n\n# Write recipe outputs\nTwi_Data_Place_Name_From_Text \u003d dataiku.Dataset(\"Twi_Data_Place_Name_From_Text\")\nTwi_Data_Place_Name_From_Text.write_with_schema(Twi_Data_Place_Name_From_Text_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "2725611 rows successfully written (qFXFFvWowm)\n",
          "name": "stdout"
        }
      ]
    }
  ]
}