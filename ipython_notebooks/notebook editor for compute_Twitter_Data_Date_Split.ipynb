{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "associatedRecipe": "compute_Twitter_Data_Date_Split",
    "creator": "admin",
    "createdOn": 1666313164275,
    "tags": [
      "recipe-editor"
    ],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# -*- coding: utf-8 -*-\nimport dataiku\nimport pandas as pd, numpy as np\nfrom dataiku import pandasutils as pdu\n\n# Read recipe inputs\nTwitter_Data_Proper \u003d dataiku.Dataset(\"Twitter_Data_Proper\")\nTwitter_Data_Proper_df \u003d Twitter_Data_Proper.get_dataframe()\n\n\n# Compute recipe outputs from inputs\n# TODO: Replace this part by your actual code that computes the output, as a Pandas dataframe\n# NB: DSS also supports other kinds of APIs for reading and writing data. Please see doc.\n\n\nTwitter_Data_Date_Split_df \u003d Twitter_Data_Proper_df # For this sample code, simply copy input to output\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 12,
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "Twitter_Data_Proper_df[\u0027date_local\u0027].str.split()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "0       [06/07/2018, 23:51]\n1        [3/15/2018, 22:00]\n2        [4/19/2018, 20:54]\n3       [12/26/2018, 18:49]\n4       [01/10/2018, 15:16]\n5        [6/21/2018, 23:21]\n6       [01/10/2019, 21:27]\n7       [10/02/2019, 18:41]\n8       [04/05/2020, 14:25]\n9         [2/21/2018, 0:57]\n10       [07/01/2019, 9:23]\n11      [12/30/2019, 20:47]\n12       [6/22/2019, 20:58]\n13       [12/25/2017, 7:47]\n14        [6/19/2018, 8:52]\n15       [12/26/2017, 7:09]\n16       [1/16/2020, 21:19]\n17      [11/24/2018, 21:03]\n18       [4/19/2019, 22:14]\n19       [9/23/2018, 18:22]\n20       [8/28/2019, 22:32]\n21       [4/29/2018, 14:39]\n22       [3/22/2018, 16:35]\n23       [12/19/2018, 5:08]\n24      [05/02/2019, 22:20]\n25      [12/31/2017, 20:50]\n26      [09/04/2019, 10:22]\n27       [7/24/2019, 18:33]\n28      [07/03/2018, 12:07]\n29      [05/09/2018, 15:33]\n30       [1/27/2018, 22:09]\n31        [2/24/2020, 2:28]\n32      [01/04/2018, 23:05]\n33       [8/29/2018, 20:45]\n34       [4/21/2020, 17:42]\n35       [9/26/2018, 11:16]\n36      [07/05/2018, 19:59]\n37      [08/08/2018, 19:56]\n38      [08/12/2019, 16:11]\n39       [6/25/2019, 14:46]\n40      [12/07/2019, 20:12]\n41       [1/26/2019, 20:58]\n42      [06/10/2018, 21:06]\n43       [7/29/2019, 19:05]\n44       [3/20/2018, 12:52]\n45       [04/03/2018, 0:47]\n46       [8/17/2020, 20:12]\n47       [12/19/2018, 2:36]\n48       [11/24/2018, 7:07]\n49       [4/28/2019, 16:26]\n50      [02/01/2018, 19:09]\n51       [7/15/2019, 21:05]\n52       [01/01/2019, 5:01]\n53       [6/28/2018, 12:59]\n54       [4/23/2019, 18:18]\n55       [11/02/2018, 7:28]\n56       [07/04/2019, 8:34]\n57       [1/18/2019, 20:20]\n58      [10/09/2018, 16:09]\n59       [3/29/2018, 20:35]\n60      [05/02/2020, 20:27]\n61      [12/15/2018, 20:03]\n62      [12/27/2017, 20:09]\n63       [2/28/2020, 20:37]\n64       [3/23/2018, 20:22]\n65       [9/20/2020, 21:18]\n66       [5/23/2018, 22:15]\n67        [3/29/2018, 8:28]\n68       [12/29/2017, 9:49]\n69       [4/29/2019, 19:41]\n70      [10/09/2018, 23:03]\n71      [11/07/2019, 14:00]\n72      [11/30/2018, 16:49]\n73       [4/17/2019, 22:49]\n74      [09/09/2019, 21:17]\n75      [01/04/2018, 21:19]\n76      [12/27/2018, 20:45]\n77       [11/03/2018, 7:41]\n78      [10/10/2018, 16:17]\n79       [1/27/2018, 18:48]\n80       [2/15/2020, 19:44]\n81      [06/05/2019, 21:39]\n82      [11/02/2018, 18:55]\n83      [09/06/2019, 19:08]\n84       [9/18/2019, 20:01]\n85       [3/23/2018, 20:59]\n86       [6/17/2018, 22:41]\n87      [07/05/2019, 11:00]\n88      [09/07/2020, 20:50]\n89      [02/06/2020, 22:29]\n90        [4/20/2019, 9:25]\n91       [4/28/2022, 12:17]\n92      [07/05/2018, 20:17]\n93       [8/21/2018, 13:31]\n94        [1/29/2018, 8:29]\n95      [03/06/2018, 13:57]\n96      [08/10/2018, 14:31]\n97       [9/20/2018, 10:05]\n98      [01/07/2020, 17:58]\n99       [9/27/2018, 17:07]\n100       [3/28/2019, 8:26]\n101     [03/06/2018, 22:12]\n102      [6/16/2018, 22:28]\n103      [2/18/2018, 22:25]\n104       [9/26/2018, 8:15]\n               ...         \n9895    [11/23/2019, 16:42]\n9896     [5/31/2018, 18:22]\n9897    [11/21/2018, 20:18]\n9898    [06/06/2019, 11:23]\n9899     [01/01/2018, 5:33]\n9900     [1/16/2018, 21:18]\n9901     [4/18/2019, 21:42]\n9902     [8/31/2018, 16:35]\n9903    [12/22/2019, 17:52]\n9904    [10/20/2020, 16:45]\n9905    [04/03/2019, 19:07]\n9906    [04/02/2019, 19:21]\n9907     [10/30/2018, 7:53]\n9908    [02/06/2018, 10:09]\n9909     [10/23/2019, 9:49]\n9910     [6/24/2019, 10:21]\n9911     [4/27/2019, 20:58]\n9912     [10/03/2019, 7:20]\n9913      [4/30/2019, 9:00]\n9914     [3/18/2018, 18:22]\n9915     [8/23/2018, 18:52]\n9916    [01/05/2020, 20:53]\n9917     [6/19/2020, 22:19]\n9918    [12/01/2018, 15:26]\n9919     [1/25/2020, 21:01]\n9920    [03/09/2018, 20:36]\n9921     [4/25/2019, 13:07]\n9922      [2/13/2018, 9:09]\n9923     [02/07/2018, 7:31]\n9924      [1/28/2018, 5:39]\n9925    [06/12/2018, 13:36]\n9926    [08/09/2018, 20:50]\n9927    [11/28/2019, 18:37]\n9928     [12/30/2017, 0:59]\n9929    [07/08/2019, 19:19]\n9930     [9/23/2018, 12:38]\n9931    [12/22/2019, 20:20]\n9932      [4/16/2018, 9:46]\n9933     [2/14/2020, 19:40]\n9934    [10/30/2018, 21:04]\n9935    [09/07/2018, 16:13]\n9936    [12/18/2019, 12:40]\n9937     [6/19/2018, 19:29]\n9938     [4/24/2019, 19:32]\n9939     [9/15/2020, 18:06]\n9940    [12/21/2018, 18:19]\n9941    [04/12/2019, 11:31]\n9942     [4/25/2019, 20:38]\n9943    [01/03/2020, 17:54]\n9944     [8/27/2018, 19:21]\n9945     [6/16/2018, 16:17]\n9946    [10/25/2018, 10:46]\n9947     [1/31/2020, 20:27]\n9948     [06/09/2018, 7:47]\n9949    [06/04/2020, 23:03]\n9950    [03/04/2021, 23:44]\n9951     [1/22/2018, 23:55]\n9952     [10/15/2019, 9:32]\n9953    [10/22/2018, 17:49]\n9954     [8/26/2018, 11:38]\n9955     [5/21/2018, 22:34]\n9956    [11/21/2018, 21:06]\n9957     [2/17/2020, 16:06]\n9958     [1/21/2020, 21:18]\n9959    [05/02/2018, 10:08]\n9960      [4/16/2018, 7:54]\n9961     [2/20/2018, 20:46]\n9962     [6/15/2019, 20:04]\n9963    [11/04/2019, 14:04]\n9964    [11/06/2019, 17:37]\n9965     [1/18/2019, 17:28]\n9966    [12/01/2019, 12:02]\n9967     [9/13/2018, 19:20]\n9968    [11/16/2018, 16:07]\n9969    [03/12/2018, 10:45]\n9970      [4/24/2018, 4:40]\n9971     [12/20/2018, 8:49]\n9972      [9/25/2019, 2:57]\n9973    [09/05/2019, 20:22]\n9974     [5/31/2020, 21:08]\n9975     [7/29/2019, 14:50]\n9976     [6/30/2018, 10:13]\n9977     [4/15/2019, 16:52]\n9978    [05/04/2019, 11:18]\n9979    [08/03/2018, 20:20]\n9980    [10/28/2018, 21:02]\n9981     [4/26/2018, 17:56]\n9982    [12/19/2019, 23:01]\n9983     [09/12/2019, 6:46]\n9984      [9/16/2018, 7:47]\n9985    [04/01/2019, 12:41]\n9986     [08/06/2018, 0:33]\n9987     [4/29/2018, 13:36]\n9988    [09/01/2018, 14:14]\n9989    [11/22/2018, 23:31]\n9990     [6/30/2018, 20:33]\n9991     [8/17/2018, 20:27]\n9992     [6/28/2019, 19:47]\n9993      [4/21/2018, 1:35]\n9994    [09/11/2018, 20:34]\n9995     [7/24/2019, 20:57]\n9996    [12/25/2019, 17:57]\n9997     [8/24/2018, 22:55]\n9998    [02/10/2018, 20:26]\n9999     [6/28/2018, 20:13]\nName: date_local, Length: 10000, dtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Twitter_Data_Proper_df[[\u0027date\u0027,\u0027time\u0027]] \u003d Twitter_Data_Date_Split_df[\u0027date_local\u0027].str.split(expand\u003dTrue)\nTwitter_Data_Proper_df \u003d Twitter_Data_Proper_df.drop({\u0027date_local\u0027}, axis\u003d1)\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 27,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n# Write recipe outputs\nTwitter_Data_Date_Split \u003d dataiku.Dataset(\"Twitter_Data_Date_Split\")\nTwitter_Data_Date_Split.write_with_schema(Twitter_Data_Date_Split_df)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "10000 rows successfully written (KgsYasRLKn)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}